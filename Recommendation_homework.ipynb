{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mosigaaa/Credit---Score/blob/main/Recommendation_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COPz6Y0pMb9D"
      },
      "source": [
        "# Homework\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/biodatlab/xlab-recommendation/blob/main/homework/homework.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jz6NNh1Mb9E"
      },
      "source": [
        "### 1. Implicit Recommendation with X-wines Dataset\n",
        "Use [X-wines](https://github.com/rogerioxavier/X-Wines/tree/main/Dataset/last) dataset for implicit recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8jkQcDAMb9E"
      },
      "source": [
        "##### Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RwwIgErfMb9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6a3c4f-aa02-4dcd-8453-ba611ce3d586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JuGLA56ibjPtzhupMxUHwA781XHT7Wml\n",
            "To: /content/XWines_Slim_1K_wines_150K_ratings.zip\n",
            "100%|██████████| 2.47M/2.47M [00:00<00:00, 219MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  XWines_Slim_1K_wines_150K_ratings.zip\n",
            "  inflating: XWines_Slim_150K_ratings.csv  \n",
            "  inflating: XWines_Slim_1K_wines.csv  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download dataset from google drive\n",
        "import gdown\n",
        "output = \"XWines_Slim_1K_wines_150K_ratings.zip\"\n",
        "url = \"https://drive.google.com/file/d/1JuGLA56ibjPtzhupMxUHwA781XHT7Wml/view?usp=drive_link\"\n",
        "gdown.download(url=url, output=output, quiet=False, fuzzy=True)\n",
        "\n",
        "# Extract dataset zip file\n",
        "!unzip XWines_Slim_1K_wines_150K_ratings.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0lOUG-HMb9F"
      },
      "outputs": [],
      "source": [
        "# TODO: Using implicit ALS model to get 10 wine recommendations for a single user.\n",
        "# - Convert the dataset into an implicit one by setting ratings lower than 4.0 (or whatever threshold) to zero and those higher than 4.0 to one.\n",
        "# - Weight the item-user sparse matrix with implicit BM25 weighting before creating an ALS model.\n",
        "# - Display the result of the model with Gradio."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install implicit\n",
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAOtbAkiODdk",
        "outputId": "5aa358e7-dbff-4ab4-b8a5-d51345bd137b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting implicit\n",
            "  Downloading implicit-0.7.2-cp310-cp310-manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from implicit) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.10/dist-packages (from implicit) (1.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from implicit) (4.66.1)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from implicit) (3.2.0)\n",
            "Installing collected packages: implicit\n",
            "Successfully installed implicit-0.7.2\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.1.1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.0 (from gradio)\n",
            "  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.6.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore (from httpx->gradio)\n",
            "  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=50531ca47db8d98007dbb800e0366a334276ddd62cb43266d0ea9739b25768fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, huggingface-hub, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gradio-4.1.1 gradio-client-0.7.0 h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 huggingface-hub-0.18.0 orjson-3.9.10 pydantic-2.4.2 pydantic-core-2.10.1 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8kbrxROaOKHB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xwine_rating_1K = pd.read_csv(\"/content/XWines_Slim_1K_wines.csv\")\n",
        "Xwine_rating_150K = pd.read_csv(\"/content/XWines_Slim_150K_ratings.csv\")\n",
        "#print(Xwine_rating_1K.head(10))\n",
        "print(Xwine_rating_150K.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MfpSWK2OYmb",
        "outputId": "9283c7c4-7315-495e-b0a5-0afab7e01b3b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   RatingID   UserID  WineID Vintage  Rating                 Date\n",
            "0       143  1356810  103471    1950     4.5  2021-11-02 20:52:59\n",
            "1       199  1173759  111415    1951     5.0  2015-08-20 17:46:26\n",
            "2       348  1164877  111395    1952     5.0  2020-11-13 05:40:26\n",
            "3       374  1207665  111433    1953     5.0  2017-05-05 06:44:13\n",
            "4       834  1075841  111431    1955     5.0  2016-09-14 20:18:38\n",
            "5       876  1211463  111395    1955     5.0  2021-12-02 23:12:49\n",
            "6      1005  1076348  111433    1955     4.5  2021-06-19 19:53:56\n",
            "7      1020  1147051  111429    1955     5.0  2018-07-08 20:09:46\n",
            "8      1029  1225931  111431    1955     5.0  2017-04-24 01:41:52\n",
            "9      1399  1197513  111415    1958     5.0  2014-07-04 01:07:16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4a2c5e755d00>:2: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  Xwine_rating_150K = pd.read_csv(\"/content/XWines_Slim_150K_ratings.csv\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xwine_rating_150K.drop(columns=[\"Date\"],inplace=True)\n",
        "\n",
        "for index, rating in Xwine_rating_150K[\"Rating\"].iteritems():\n",
        "    if rating > 4:\n",
        "        Xwine_rating_150K.at[index, \"Rating\"] = 1\n",
        "    else:\n",
        "       Xwine_rating_150K.at[index, \"Rating\"] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbLbnhgVQ2Qn",
        "outputId": "ef367744-944a-4071-8be5-f5f04642cad9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-dffef22c8b4c>:3: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for index, rating in Xwine_rating_150K[\"Rating\"].iteritems():\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Xwine_rating_150K[\"Rating\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTrs0Ml6Kslq",
        "outputId": "5648ea97-1fd3-4799-8c9b-9a834fa975b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    116442\n",
            "1.0     33558\n",
            "Name: Rating, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import NMF\n",
        "from scipy.sparse import csr_matrix\n",
        "from implicit.nearest_neighbours import bm25_weight"
      ],
      "metadata": {
        "id": "iYSHWfXZMn1a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xwine_rating_150K[\"Rating\"] = Xwine_rating_150K[\"Rating\"].astype(float)\n",
        "Xwine_rating_150K[\"UserID\"] = Xwine_rating_150K[\"UserID\"].astype(\"category\")\n",
        "Xwine_rating_150K[\"WineID\"] = Xwine_rating_150K[\"WineID\"].astype(\"category\")"
      ],
      "metadata": {
        "id": "7oC9sY_6NFM6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_rating = csr_matrix( (\n",
        "    Xwine_rating_150K[\"Rating\"],(Xwine_rating_150K[\"UserID\"].cat.codes,Xwine_rating_150K[\"WineID\"].cat.codes)\n",
        "    )\n",
        ")\n",
        "X_rating = X_rating.tocsr()\n",
        "print(X_rating)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVTXfqXzOFjU",
        "outputId": "53065414-04e9-485b-c031-cbbee107986a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 68)\t0.0\n",
            "  (0, 161)\t0.0\n",
            "  (0, 191)\t0.0\n",
            "  (0, 195)\t0.0\n",
            "  (0, 197)\t1.0\n",
            "  (0, 199)\t1.0\n",
            "  (0, 204)\t0.0\n",
            "  (0, 206)\t0.0\n",
            "  (0, 215)\t1.0\n",
            "  (0, 218)\t1.0\n",
            "  (0, 270)\t0.0\n",
            "  (0, 382)\t0.0\n",
            "  (0, 399)\t0.0\n",
            "  (0, 418)\t0.0\n",
            "  (0, 439)\t0.0\n",
            "  (0, 521)\t0.0\n",
            "  (0, 522)\t0.0\n",
            "  (0, 545)\t0.0\n",
            "  (0, 560)\t0.0\n",
            "  (0, 642)\t0.0\n",
            "  (0, 649)\t0.0\n",
            "  (0, 717)\t1.0\n",
            "  (0, 765)\t1.0\n",
            "  (0, 783)\t0.0\n",
            "  (0, 811)\t0.0\n",
            "  :\t:\n",
            "  (10559, 211)\t0.0\n",
            "  (10559, 226)\t0.0\n",
            "  (10559, 243)\t0.0\n",
            "  (10559, 353)\t0.0\n",
            "  (10559, 563)\t1.0\n",
            "  (10559, 637)\t0.0\n",
            "  (10559, 642)\t0.0\n",
            "  (10559, 652)\t0.0\n",
            "  (10559, 781)\t0.0\n",
            "  (10559, 920)\t0.0\n",
            "  (10559, 923)\t0.0\n",
            "  (10560, 53)\t0.0\n",
            "  (10560, 63)\t0.0\n",
            "  (10560, 141)\t0.0\n",
            "  (10560, 204)\t1.0\n",
            "  (10560, 210)\t0.0\n",
            "  (10560, 220)\t0.0\n",
            "  (10560, 237)\t0.0\n",
            "  (10560, 256)\t0.0\n",
            "  (10560, 264)\t0.0\n",
            "  (10560, 377)\t0.0\n",
            "  (10560, 516)\t0.0\n",
            "  (10560, 641)\t0.0\n",
            "  (10560, 906)\t1.0\n",
            "  (10560, 912)\t0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from implicit.nearest_neighbours import bm25_weight\n",
        "\n",
        "X_rating = bm25_weight(X_rating, K1=100, B=0.8)\n",
        "print(X_rating)\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "model = AlternatingLeastSquares(factors=64, regularization=0.05, alpha=2.0)\n",
        "# Implicit expect user-item (user-artist)\n",
        "user_rating = X_rating.T.tocsr()\n",
        "\n",
        "model.fit(user_rating)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934,
          "referenced_widgets": [
            "254dcd6d8fcb4f45953b441baaaff73b",
            "f764ae7b777a4cc68068065397bf10f8",
            "01bd905565f94ae893e1538b2a6b6790",
            "bbc57b5e7eee4480856f428b34f5217d",
            "ef8f747de8074503adc346c42968fbdf",
            "cc165ef3f9ce48b3b253d0060e516242",
            "cd9cc4b95bf246349b3f8d3af8099283",
            "1050d6e1fb694e11aadeb97fd4309847",
            "e9c3b2f298144a9ebc92ff617faf5646",
            "744cafa6672f4c81931c663d1a6026d1",
            "a1f1df7d600e4dcc944ecfb1ff13cf39"
          ]
        },
        "id": "z3S2_QKyPIRh",
        "outputId": "f724852a-d900-4bbe-9ca8-742f19bdf045"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 68)\t0.0\n",
            "  (0, 161)\t0.0\n",
            "  (0, 191)\t0.0\n",
            "  (0, 195)\t0.0\n",
            "  (0, 197)\t112.0345526687692\n",
            "  (0, 199)\t96.28680155720033\n",
            "  (0, 204)\t0.0\n",
            "  (0, 206)\t0.0\n",
            "  (0, 215)\t140.31743599945386\n",
            "  (0, 218)\t167.1898101545216\n",
            "  (0, 270)\t0.0\n",
            "  (0, 382)\t0.0\n",
            "  (0, 399)\t0.0\n",
            "  (0, 418)\t0.0\n",
            "  (0, 439)\t0.0\n",
            "  (0, 521)\t0.0\n",
            "  (0, 522)\t0.0\n",
            "  (0, 545)\t0.0\n",
            "  (0, 560)\t0.0\n",
            "  (0, 642)\t0.0\n",
            "  (0, 649)\t0.0\n",
            "  (0, 717)\t123.8302282565163\n",
            "  (0, 765)\t81.4841587608406\n",
            "  (0, 783)\t0.0\n",
            "  (0, 811)\t0.0\n",
            "  :\t:\n",
            "  (10559, 211)\t0.0\n",
            "  (10559, 226)\t0.0\n",
            "  (10559, 243)\t0.0\n",
            "  (10559, 353)\t0.0\n",
            "  (10559, 563)\t201.51758380611193\n",
            "  (10559, 637)\t0.0\n",
            "  (10559, 642)\t0.0\n",
            "  (10559, 652)\t0.0\n",
            "  (10559, 781)\t0.0\n",
            "  (10559, 920)\t0.0\n",
            "  (10559, 923)\t0.0\n",
            "  (10560, 53)\t0.0\n",
            "  (10560, 63)\t0.0\n",
            "  (10560, 141)\t0.0\n",
            "  (10560, 204)\t178.03714296097837\n",
            "  (10560, 210)\t0.0\n",
            "  (10560, 220)\t0.0\n",
            "  (10560, 237)\t0.0\n",
            "  (10560, 256)\t0.0\n",
            "  (10560, 264)\t0.0\n",
            "  (10560, 377)\t0.0\n",
            "  (10560, 516)\t0.0\n",
            "  (10560, 641)\t0.0\n",
            "  (10560, 906)\t142.5782474781955\n",
            "  (10560, 912)\t0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "254dcd6d8fcb4f45953b441baaaff73b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jEHOKSNWPtB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def recommend_wine(user_id):\n",
        "    user_id = int(user_id)\n",
        "    if (\n",
        "        Xwine_rating_150K[\"UserID\"] == user_id\n",
        "    ).any():  # check if input user_id exist in dataset or not\n",
        "        selected_user_df = Xwine_rating_150K[Xwine_rating_150K[\"UserID\"] == user_id].sort_values(\n",
        "            by=\"Rating\", ascending=False\n",
        "        )\n",
        "\n",
        "        # Get the user index for the user_id to use in the prediction\n",
        "        user_idx = selected_user_df[\"UserID\"].cat.codes.values[0]\n",
        "        predicted_ratings = np.dot(W[user_idx], H)\n",
        "        sort_rating_indices = np.flip(np.argsort(predicted_ratings))[:20]\n",
        "        selected_predict_ratings = predicted_ratings[sort_rating_indices]\n",
        "\n",
        "        # Get the WineID from the sorted indices\n",
        "        rec_wine_ids = Xwine_rating_150K[\"WineID\"].cat.categories[sort_rating_indices]\n",
        "\n",
        "        rec_df = pd.DataFrame({\n",
        "            \"WineID\": rec_wine_ids,\n",
        "            \"PredictedRating\": selected_predict_ratings,\n",
        "        })\n",
        "\n",
        "        # Merge with the original dataset to get additional wine details\n",
        "        rec_df = rec_df.merge(Xwine_rating_150K.drop_duplicates(subset=['WineID']), how=\"left\", on=\"WineID\")\n",
        "\n",
        "        # Return the top 10 actual ratings by the user and top 10 recommendations\n",
        "        return selected_user_df.head(10), rec_df.head(10)\n",
        "    else:\n",
        "        raise gr.Error(\"User ID not found\")\n",
        "\n",
        "# Gradio interface setup\n",
        "demo = gr.Interface(\n",
        "    fn=recommend_wine,\n",
        "    inputs=gr.Textbox(label=\"Input UserID (e.g., from 1 - 610)\"),\n",
        "    outputs=[gr.DataFrame(label=\"User's Rated Wines\"), gr.DataFrame(label=\"Recommended Wines\")],\n",
        "    examples=[\"21\", \"50\"],\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "EjuTgUZ3RtD6",
        "outputId": "2ba072ce-ce38-455d-fea6-774ceb9f82f8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://4311dbb0f6ece6ebfd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4311dbb0f6ece6ebfd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umCQPE7kMb9F"
      },
      "source": [
        "### 2. Using CLIP to embed product images and recommend similar items\n",
        "Use [fashion-product-images](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset) dataset for CLIP image search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DotjusjBMb9G"
      },
      "source": [
        "* Dataset: https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset\n",
        "* Interface with Kaggle API: https://www.kaggle.com/discussions/general/74235"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkHA5YusMb9G"
      },
      "source": [
        "##### Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dx5CBoFiMb9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e97eb1-9e05-48ca-91b1-5f804de6b3e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jDBJUKJqMb9G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b1d7bb28-98ce-4c0c-ccd0-0a09f4fbc556"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-341dd073-ebd4-412b-a422-2159e3fbdbf6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-341dd073-ebd4-412b-a422-2159e3fbdbf6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"makkawanchaimongkol\",\"key\":\"c6687734fccb0256c9f2f480547ab078\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# follow the \"interface with Kaggle API\" link, upload kaggle.json\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EQnJFu_hMb9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a23e3377-2781-4faa-e091-5a538a0d1827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "oS8GOOXuMb9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64fabe33-92ca-47e7-cbfe-b9c0a9d2d886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                         title                                             size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "iamsouravbanerjee/customer-shopping-trends-dataset          Customer Shopping Trends Dataset                 146KB  2023-10-05 06:45:37          19388        411  1.0              \n",
            "prasad22/healthcare-dataset                                 Healthcare Dataset                               483KB  2023-10-31 11:30:58            793         25  1.0              \n",
            "rajatsurana979/fast-food-sales-report                       Restaurant Sales report                          122KB  2023-11-06 20:46:39            924         31  1.0              \n",
            "nelgiriyewithana/billionaires-statistics-dataset            Billionaires Statistics Dataset (2023)           139KB  2023-09-29 13:39:28          10598        259  1.0              \n",
            "redpen12/employees-satisfaction-analysis                    Employee Satisfaction Survey Data                140KB  2023-11-03 08:56:49           1029         28  1.0              \n",
            "joebeachcapital/30000-spotify-songs                         30000 Spotify Songs                                3MB  2023-11-01 06:06:43           1367         38  1.0              \n",
            "nelgiriyewithana/world-educational-data                     World Educational Data                             9KB  2023-11-04 06:10:17            771         31  1.0              \n",
            "zeesolver/consumer-behavior-and-shopping-habits-dataset     Consumer Behavior and Shopping Habits Dataset:   146KB  2023-10-19 13:36:26           3716         60  1.0              \n",
            "victorahaji/worlds-air-quality-and-water-pollution-dataset  World's Air Quality and Water Pollution Dataset   58KB  2023-10-30 12:37:47           1808         41  0.9411765        \n",
            "samyakb/student-stress-factors                              Student stress factors                            887B  2023-11-02 12:42:11           1370         42  0.9411765        \n",
            "thedrcat/daigt-proper-train-dataset                         DAIGT Proper Train Dataset                       119MB  2023-11-05 14:03:25            237         61  1.0              \n",
            "sujaykapadnis/hollywood-hits-and-flops-2007-2023            Hollywood Hits and Flops [2007 - 2023]           204KB  2023-10-26 13:04:38            901         29  1.0              \n",
            "alejopaullier/daigt-external-dataset                        DAIGT | External Dataset                           3MB  2023-10-31 19:11:35            316         77  0.7647059        \n",
            "prasad22/retail-transactions-dataset                        Retail Transactions Dataset                        1MB  2023-11-01 04:53:38            818         24  1.0              \n",
            "amirmahdiabbootalebi/salary-by-job-title-and-country        Salary by Job Title and Country                   37KB  2023-11-02 06:37:13            827         30  1.0              \n",
            "dhavalrupapara/nba-2023-player-shot-dataset                 NBA Player Shot Dataset (2023)                    60KB  2023-10-23 11:40:22           1014         28  1.0              \n",
            "antimoni/metabolic-syndrome                                 Metabolic Syndrome                                49KB  2023-10-27 17:52:41            716         33  1.0              \n",
            "anshtanwar/monthly-food-price-estimates                     Global Food Price Inflation                      254KB  2023-10-21 15:33:25           6112         99  1.0              \n",
            "iamsouravbanerjee/heart-attack-prediction-dataset           Heart Attack Risk Prediction Dataset             519KB  2023-09-27 07:07:50           7225        131  1.0              \n",
            "nelgiriyewithana/credit-card-fraud-detection-dataset-2023   Credit Card Fraud Detection Dataset 2023         143MB  2023-09-18 10:00:19          10869        301  1.0              \n"
          ]
        }
      ],
      "source": [
        "# test access kaggle dataset\n",
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "clTsbIljMb9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e60fc16-430e-4174-cc20-b377edc36ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fashion-product-images-small.zip to /content\n",
            " 99% 562M/565M [00:19<00:00, 33.2MB/s]\n",
            "100% 565M/565M [00:19<00:00, 30.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download dataset\n",
        "\n",
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtbOHhe1Mb9G"
      },
      "outputs": [],
      "source": [
        "# extract dataset zip file\n",
        "\n",
        "!unzip fashion-product-images-small.zipฤ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch ftfy regex tqdm numpy\n",
        "! pip install openai-clip\n",
        "! pip install gradio\n",
        "! pip install gdown"
      ],
      "metadata": {
        "id": "V4vF2GCN54wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as op\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "import clip\n",
        "# check available runtime\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if device == \"cuda\":\n",
        "  ! pip install faiss-gpu\n",
        "else:\n",
        "  ! pip install faiss-cpu\n",
        "\n",
        "print(\"Now running with \" + device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUpPBL0V6V0B",
        "outputId": "2e0ff0ef-e4c6-4b40-900f-f52d1abafcc0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n",
            "Now running with cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clip.available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2O0BiQo6n5z",
        "outputId": "b3a73629-dd51-4f94-a946-d1d28d00b3f8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdpcuuGo6pme",
        "outputId": "f4e0f930-e1c1-448b-cf1c-eb0a7c7d2cce"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:12<00:00, 28.8MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "\n",
        "dataset_path = op.join(os.getcwd(), \"/content/myntradataset/images/\")\n",
        "print(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqAkZCfS7hQO",
        "outputId": "aac341c4-5bb8-4066-ed6e-e3af9dcdb325"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/myntradataset/images/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of all filename in dataset folder\n",
        "\n",
        "all_folder_path = os.listdir(dataset_path)\n",
        "all_folder_path.sort()\n",
        "print(len(all_folder_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7TfCR5x7pDT",
        "outputId": "ee4e82f0-c950-4315-87bc-4b7e7a0a79e3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# allocate embeddings array from num_file\n",
        "embeddings_storage = np.zeros((len(all_folder_path),512),dtype=np.float32)\n",
        "\n",
        "# encoder dataset & store images name\n",
        "file_counter = 0\n",
        "images_path = [f for f in os.listdir(dataset_path) if op.isfile(op.join(dataset_path, f))]\n",
        "images_path.sort()\n",
        "for path in tqdm(images_path):\n",
        "    with torch.no_grad():\n",
        "        image = (\n",
        "            preprocess(Image.open(op.join(dataset_path, path))).unsqueeze(0).to(device)\n",
        "        )\n",
        "        embeddings_storage[file_counter] = np.array(\n",
        "            model.encode_image(image).numpy(force=True)[0].astype(\"float32\")\n",
        "        )\n",
        "        file_counter += 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFWt9W-F8KDv",
        "outputId": "d0fbddb7-9b30-4c1d-cc30-f1eb0f2cc9c5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44441/44441 [12:00<00:00, 61.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create embeddings vector using FAISS\n",
        "\n",
        "import faiss\n",
        "\n",
        "index = faiss.IndexFlatL2(\n",
        "    512\n",
        ")  # dimension of 1 embedding decoded from CLIP model is 512\n",
        "index.add(embeddings_storage)\n",
        "print(index.ntotal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJU8KVR6Frew",
        "outputId": "1edafb28-fcc5-41c5-db83-38f428acf0b5"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os.path as op\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "def recommend_similar_image(image_path):\n",
        "    print(f\"get image path {image_path}\")\n",
        "\n",
        "    test_image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_embeddings = model.encode_image(test_image).numpy(force = True)[0].astype(\"float32\")\n",
        "        test_embeddings = np.array([test_embeddings])\n",
        "\n",
        "    k = 4  # number of recommendations\n",
        "    square_distance, image_index = index.search(test_embeddings, k)\n",
        "    print(image_index)\n",
        "    print(square_distance)\n",
        "\n",
        "    print(\"Opening Images...\")\n",
        "    recommended_images = [\n",
        "        (\n",
        "            Image.open(op.join(dataset_path, all_folder_path[image_index[0][i]])),\n",
        "            f\"Recommended Rank {i+1}\",\n",
        "        )\n",
        "        for i in range(k)\n",
        "    ]\n",
        "    return recommended_images\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=recommend_similar_image,\n",
        "    inputs=gr.Image(type=\"filepath\"),\n",
        "    outputs=gr.Gallery(),\n",
        ").launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "UvUWCEhBF4oL",
        "outputId": "866fae34-1aa7-4b1a-e527-fb4ed071a442"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://4e8e1a3b5bf3ec3be4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4e8e1a3b5bf3ec3be4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get image path /tmp/gradio/941c0fffed299a38aa131564a19d0d739f3ece66/image.png\n",
            "[[    6 41468 15906 42396]]\n",
            "[[ 0.       10.718597 11.229553 14.982812]]\n",
            "Opening Images...\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://4e8e1a3b5bf3ec3be4.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_similar_image(text):\n",
        "\n",
        "    text = clip.tokenize([text]).to(device)\n",
        "    with torch.no_grad():\n",
        "        test_embeddings = model.encode_text(text).numpy(force=True)[0].astype(\"float32\")\n",
        "        test_embeddings = np.array([test_embeddings])\n",
        "\n",
        "    k = 10  # number of recommendations\n",
        "    square_distance, image_index = index.search(test_embeddings, k)\n",
        "    print(image_index)\n",
        "    print(square_distance)\n",
        "\n",
        "    print(\"Opening Images...\")\n",
        "    recommended_images = [\n",
        "        (\n",
        "            Image.open(op.join(dataset_path, all_folder_path[image_index[0][i]])),\n",
        "            f\"Recommended Rank {i+1}\",\n",
        "        )\n",
        "        for i in range(k)\n",
        "    ]\n",
        "    return recommended_images\n",
        "\n",
        "\n",
        "example_path = []\n",
        "demo = gr.Interface(\n",
        "    fn=recommend_similar_image,\n",
        "    inputs=gr.Textbox(),\n",
        "    outputs=gr.Gallery(),\n",
        ").launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rAUFW5JbNgr-",
        "outputId": "57c1e12b-d082-449e-f1c6-5c3696c30a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://0d58e9a8da8d422b44.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0d58e9a8da8d422b44.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[11286 33505 25976 12611 42482 13143  2598 20572 31812 17311]]\n",
            "[[119.534355 120.381744 120.83953  122.36725  123.34304  123.40774\n",
            "  123.564995 123.65398  123.70002  123.93276 ]]\n",
            "Opening Images...\n",
            "[[  661 28304 41571 38655 28299 16776 42585 42442 27336 28590]]\n",
            "[[176.1723  179.19489 179.34119 179.75227 180.8226  181.25922 181.40344\n",
            "  181.49213 181.76077 182.04488]]\n",
            "Opening Images...\n",
            "[[34227 28590 32743 42585  3796  4570 11286 28593 28895 11163]]\n",
            "[[166.98631 167.86702 167.96751 167.99074 168.2092  168.29666 168.35619\n",
            "  168.37315 168.41467 168.43793]]\n",
            "Opening Images...\n",
            "[[28081 43800 41571 28304 28299 37329 12611 28047 42442 11958]]\n",
            "[[151.98413 152.98402 153.1293  154.42413 154.8538  154.895   155.10371\n",
            "  155.32512 155.42017 155.5368 ]]\n",
            "Opening Images...\n",
            "[[20948 37351  9431 26266  4401  3125 30951 16603 38866  2516]]\n",
            "[[127.45049 128.10587 128.65756 128.78375 129.0273  129.19585 129.55028\n",
            "  129.66087 129.70586 129.72473]]\n",
            "Opening Images...\n",
            "[[28360 37329 28304 41571  3745 38866 41568 28299 22222  9431]]\n",
            "[[181.58086 182.17421 182.2138  182.54065 183.07964 184.16405 184.3355\n",
            "  184.41754 184.60477 184.65927]]\n",
            "Opening Images...\n",
            "[[28304 42553 27342 28299 27336  9431 35947 36277 27430 12005]]\n",
            "[[111.751495 113.92323  114.2082   114.55241  114.563675 114.63436\n",
            "  115.585724 116.034195 116.07311  116.1381  ]]\n",
            "Opening Images...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "254dcd6d8fcb4f45953b441baaaff73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f764ae7b777a4cc68068065397bf10f8",
              "IPY_MODEL_01bd905565f94ae893e1538b2a6b6790",
              "IPY_MODEL_bbc57b5e7eee4480856f428b34f5217d"
            ],
            "layout": "IPY_MODEL_ef8f747de8074503adc346c42968fbdf"
          }
        },
        "f764ae7b777a4cc68068065397bf10f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc165ef3f9ce48b3b253d0060e516242",
            "placeholder": "​",
            "style": "IPY_MODEL_cd9cc4b95bf246349b3f8d3af8099283",
            "value": "100%"
          }
        },
        "01bd905565f94ae893e1538b2a6b6790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1050d6e1fb694e11aadeb97fd4309847",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9c3b2f298144a9ebc92ff617faf5646",
            "value": 15
          }
        },
        "bbc57b5e7eee4480856f428b34f5217d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_744cafa6672f4c81931c663d1a6026d1",
            "placeholder": "​",
            "style": "IPY_MODEL_a1f1df7d600e4dcc944ecfb1ff13cf39",
            "value": " 15/15 [00:00&lt;00:00, 153.03it/s]"
          }
        },
        "ef8f747de8074503adc346c42968fbdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc165ef3f9ce48b3b253d0060e516242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd9cc4b95bf246349b3f8d3af8099283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1050d6e1fb694e11aadeb97fd4309847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9c3b2f298144a9ebc92ff617faf5646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "744cafa6672f4c81931c663d1a6026d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f1df7d600e4dcc944ecfb1ff13cf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}